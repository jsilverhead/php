#### Leaking Bucket
Принцип очереди (FIFO), которая путём образования очереди запроса не даёт пропустить запросы.

----
#### Token Bucket
Аналогично принципу ниже, однако запрос обладает token (например timestamp), чтобы отбрасывать устаревшие запросы.

----
#### Fixed Window
Используется окно, равное n секундам. Каждый входящий запрос увеличивает счётчик.
Если запрос не вписался в счётчик - запрос отбрасывается.
Обрабатывает только свежие запросы, не зависая на обработке старых.

----
#### Sliding Log
Отслеживает временные метки каждого запроса пользователя и записываются в hash-set или таблицу и сортируются по времени.

Записи за пределами отслеживаемого интервала отбрасываются.

При запросе вычисляется количество записей для определения частоты запросов. Если выходит за рамки - отрбарсывается.

Даёт строгое ограничение скорости. Отслеживая каждого клиента в отдельности, не возникает пикового роста нагрузки в определённый моменты.

Но хранить инфу о каждом запросе может быть дорого.

----
#### Sliding Window
Гибридный вариант fixed window и sliding log.

Позволяет сохранять высокую производительность.

----
#### Глобальная политика синхронизации
Чем больше узлов, тем больше вероятность пользователю превысить лимит.
Настроить sticky session на балансировщике, чтобы пользователь направлялся на один и тот же узел.

Но такой вариант мешает масштабированию, когда узлы кластера перегружены.

Решением для гибкого распределения нагрузки является использование централизованного хранилища данных. В нём можно хранить счётчики количество запросов для каждого окна и пользователя.

----
#### Race Conditions
Появляется при конкурентных запросах и использовании централизованном хранилище.
Возникает, когда используется естественный подход `get-then-set`, при котором извлекается текущий счётчик, увеличивается и посылается обратно в хранилище.

Проблема в том, что во время выполнения цикла - могут поступать другие операции и потом сохранение данных счётчика будет ниже чем реальное значение запросов.

То есть юзер может отправить больше запросов чем ограничит rate limiting.

Лучший подход `set-then-get` - опирающийся на атомарные операторы, что позволяет увеличивать и проверять значение счётчика не мешая атомарным операциями.

**Пример:**

Представим два потока, которые одновременно увеличивают значение общей переменной counter:

```
Поток 1:
1. Читает значение counter (допустим, 0)
2. Увеличивает значение на 1 (становится 1)
3. Записывает новое значение counter (1)

Поток 2:
1. Читает значение counter (0)
2. Увеличивает значение на 1 (становится 1)
3. Записывает новое значение counter (1)
```

А по итогу можем получить:
```
• Поток 1 читает counter (0)
• Поток 2 читает counter (0)
• Поток 1 увеличивает и записывает counter (1)
• Поток 2 увеличивает и записывает counter (1)
```

----
#### Оптимизация производительности
Другой проблемой является круговая задержка (`round-trip time`), связаная с увеличением времени на проверку счётчиков.
Такое может случиться даже в Redis.

Необходимо выполнять проверки в локальной памяти. Это можно сделать, ослабив условия проверки скорости и используя `последовательную модель`.

Например, каждый узел может создать цикл синхронизации данных, в котором будет синхронизироваться с событием.
Каждый узел периодически передаёт значение счётчика для каждого пользователя и окна.
Затем узел может получить новые значение и обновить данные в локальной памяти.
При таком цикле все узлы кластера будут находиться в актуальном состоянии.

Период синхронизации узлов должен быть настраиваемым. Более короткие интервалы синхронизации приведут к меньшему расхождению данных, когда нагрузка равномерно распределятся между узлами кластера (например по принципу `round robin`). А длинные интервалы создают меньше нагрузки.

----
#### Round robin
Каждый элемент получает равную долю времени или ресурсов в циклическом порядке.
Такой формат алгоритма используется при балансировке запросов.