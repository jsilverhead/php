Брокер сообщений позволяет элементам системы "общаться" друг с другом с помощью посредника, что снимает нагрузку с сервисов.

В брокере сообщений используется две сущности:
- Producer (издатель сообщений)
- Consumer (потребитель сообщений)

Producer → Очередь → Потребитель

Два варианта отправки сообщения:
1. Напрямую - каждое сообщение используется однократно
2. Схема подписки/публикации - сообщения отправляются в определённый топик и, все подписанные на топик забирают сообщения

**Брокеры нужны**:
- Для организации связи между службами
- Засчёт асинхронной обработки задач можно увеличить производительность системы в целом
- Обеспечение надёжности доставки сообщений

**Недостатки брокеров**:
- Усложнение системы, возникает зависимость от надёжности распределённой сети
- Могут возникать ошибки, которые вызывает асинхронность, и их сложно отследить
- Освоение подобных систем

**Польза брокера**:
- Если в рамках системы есть действия, которые требуют для своего выполнения много времени и потребляют много ресурсов, но не требуют мнгновенного результата.
- Микросервисы - для координации сложных систем, состоящих из микросервисов лучше использовать брокеры сообщений
- Пуш-уведомления
- Транзакционные системы с множеством этапов, которые выполняет отдельный элемент системы

#### Redis
In-memory хранилище, которое можно использовать как брокер через **Pub**/**Sub** (без сохранения) или **Streams** (с хранением.
Протокол: RESP

**RESP** - Redis Serialization Protocol
Особенности:
- Текстовый протокол (легко читать и отлаживать)
- Поддерживает команды типа PUBLISH, SUBSCRIBE, XADD (для Streams)
- Но: Redis изначально не брокер, потому Pub/Sub и Streams это "надстройки" над хранилищем

Плюсы:
- Высокая скорость (in-memory, ~1M ops/sec)
- Простота (легко запустить, нет сложной настройки)
- Поддержка **Streams** (как в Kafka, но проще)

Минусы:
- Pub/Sub не сохраняет сообщения (если подписчик отключён, то сообщения теряются)
- Streams менее надёжный в отличии от Kafka (нет репликации между кластерами)
- Нет сложной маршрутизации как в RabbitMQ

Когда пригождаются:
- Онлайн-уведомления (чаты, real-time события)
- Кэширование + Pub/Sub (если не критична потеря сообщений)
- Простые сценарии Streams (когда Kafka избыточна)

Установка:
```bash
docker run -d --name redis -p 6379:6479 redis
```

Установка бандла:
```bash
comspoer require predis/predis
composer require symfony/redis-messenger
```

Конфигурация:
```yaml
framework:
	messenger:
		transports:
			redis_stream: 'redis://localhost:6479/messages'
		routing:
			App\Message\NotificationMessage: redis_stream
```

Отправка через Pub/Sub:
```php
class RedisController extends AbstractController
{
	private Cilent $redis;

	public function __construct(Client $redis)
	{
		$this->redis = $redis;
	}

	public function publishMessage(): Response
	{
		$this->redis->publish('notifications', json_encode(['message' => 'Hello!']));

		return new Response('Message published');
	}
}
```

Подписка на сообщения:
```bash
redis-cli subscribe notifications
```

Или в PHP через:
```php
$redis->subscribe();
```

Отправка через Redis Streams:
```php
class RedisController extends AbstractController
{
	private Client $redis;

	public function __construct(Client $redis)
	{
		$this->redis = $redis;
	}

	public function __invoke(): Response
	{
		$this->redis->xadd('motifiction_stream', '*', ['message' => 'Hello!']);

		return new Response('Added to stream');
	}
}
```

Чтение из Stream:
```php
$messages = $this->redis->xread(['notifications_stream' => '0'], 10, 3000);

// 0 - читать все новые сообщения, начиная с самого первого
// можно указать ID сообщения и чтение начнётся с этого места
// $ - читать только новые сообщения
// 10 - лимит сообщений, которое можно получить за один запрос
// 3000 - ждать 30 секунд, если нет сообщений
```

Разница между Pub/Sub и Streams:
- Streams - это лог сообщений, где данные о сообщениях хранятся и их можно перечитывать.
- Это вещание в реальном времени без сохранения.
#### RabbitMQ
Классический брокер сообщений на основе обменников и очередей.

Модели обмена: Pub/Sub, очереди, RPC
Протокол: AMQP (также поддерживает MQTT, STOMP)

**AMQP** - Advanced Messaging Queuing Protocol, годен для финансовых операций (надёжность, гарантия доставки)
Особенности AMQP:
- Поддержка сложных сценариев (очереди, обменники, routing)
- Подтверждения (ack), транзакции и персистентность

**MQTT** - Message Queuing Telemetry Transport
Создан для IoT (малый трафик, работа на слабых устройствах)
Особенности MQTT:
- Лёгкий (минимум заголовков)
- Pub/Sub с топиками
- Нет сложного routing, только топики

**STOMP** - Simple Text Oriented Messaging Protocol
Создан для простоты (текстовый протокол как HTTP)
Особенности STOMP:
- Команды в виде текста (SEND, SUBSCRIBE)
- Нет встроенных гарантий доставки (можно реализовать поверх)

**Подтверждения получения (ack)**:
Ack (acknowledgment)
- Механизм, при котором потребитель (consumer) явно подтверждает что обработал сообщение чтобы брокер знал когда сообщение можно удалить из очереди
- Виды ack:
	- ack - сообщение обработано, можно удалять
	- nack - сообщение НЕ обработано (вернуть в очередь)
	- reject - отклонить (аналог nack)

DLQ (Dead Letter Queue)
- Очередь "мёртвых" сообщений
- Очередь, куда попадают сообщения, которые:
	- Не были обработаны после N попыток
	- Истёк их TTL
	- Были явно отклонены (reject, nack)
- Позволяет не терять сообщения и анализировать ошибки

Плюсы:
- Гибкость: поддерживает разные паттерны (очереди, Pub/Sub, routing)
- Надёжность:  подтверждение (ack), персистентность, реаликация очередей.
- Удобное управление: веб-интерфейс, CLI, HTTP API
- Подходит для сложных маршрутизаций (например разные обработчики для разных типов сообщений)

Минусы:
- Менее производительный, чем Kafka при высоких нагрузках (десятки тысяч сообщений в секунду)
- нет встроенной долгосрочной истории сообщений (в отличии от Kafka)

Когда пригождается:
- Транзакционные задачаи (например, обработка платежей)
- Сложная марщрутизация (разные подписчики на разные события)
- Системы, где важна надёжность доставки (ack, retry, DLQ)

Установка:
```bash
docker run -d --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:management
```

(Доступ к админке: `http://localhost:15672`, логин/пароль: `guest`/`guest`).

Установка бандла в Symfony:
```bash
composer require php-amplib/rabbitmq-bundle
```

Конфигурация:
```yaml
old_sound_rabbit_mq:
	connections:
		default:
			host: '%env(RABBITMQ_HOST)%'
			port: '%env(RABBITMQ_PORT)%'
			user: '%env(RABBITMQ_USER)%'
			password: '%env(RABBITMQ_PASSWORD)%'
	producers:
		email_notification:
			connection: default
			exchange_options: { name: 'notifications', type: direct }
	consumers:
		email_consumer:
			connection: default
			exchange_options: { name: 'notifications', type: direct }
			queue_options: { name: 'email_queue' }
			callback: App\MessageHandler\EmailNotificationHandler
```

Создание producer (отправка сообщений):
```php
class NotificationController extends AbstractController
{
	private ProfucerInterface $emailProducer;
	
	public function __construct(ProducerInterface $emailProducer)
	{
	$this->emilProducer = $emailProducer;
	}

	public function __invoke(): Response
	{
		$this->emailProducer->publish(json_encode(['email' => 'user@example.com', 'message' => 'Hello!']))

	return new Response('Message sent!');
	}
}
```

Создание Consumer (обработка сообщений):
```php
class EmailNotificationHandler
{
	public function __construct(private MailerInteface $mailer)
	{
	}

	public function execute(AMQMessage $msg): void
	{
		$data = json_decode($msg->body, true);

		$email = (new Email())
		->from('noreply@example.com')
		->to($data['email'])
		->subject('New Notification')
		->text($data['message']);

		$this->mailer->send($email);

		echo 'Email sent';
	}
}
```

Запуск consumer:
```bash
php bin/console rabbitmq:consumer email_consumer -vvv
```
#### Kafka
Распределённый лог-ориентированный брокер (сообщения хранятся в виде логов)

Модели обмена: Pub/Sub с хранением истории
Протокол: Свой бинарный протокол поверх TCP

**Бинарный протокол**
Создан для максимальной производительности
Особенности:
- Данные предоставляются в бинарном виде
- Свой формат, оптимизированный под Kafka
- Клиенты должен знать спецификацию протокола

Плюсы:
- Высокая пропускная способность (миллионы сообщений в секунду)
- Хранение истории (сообщения хранятся долго, их можно перечитывать)
- Горизонтальное масштабирование (партиции, репликация)
- Поддержка потоковой обработки (Kafka Streams, Flink)

Миунсы:
- Сложнеее в настройке и администрировании (Zookeeper, брокеры, партиции)
- Нет гибкой маршрутизации как в RabbitMQ.
- Избыточен для простых сценариев.

Когда пригождается:
- Обработка больших потоков данных (логи, метрики, события).
- Стримминг данных (аналитика в реальном времени)
- Сценарии, где важна история сообщений (аудит, повторная обработка)

----
Протокол в рамках брокера - набор правил, по которым клиент и сервер обмениваются сообщениями.
Он определяет:
1. Формат сообщений (как структурированы данные)
2. Способ доставки (синхронный/асинхронный, подтверждения)
3. Авторизацию и безопасность (TLS, логины/пароли)
4. Семантику операций (как создать очередь, как подписаться)

Нужен для:
- Клиенты на разных языках могли работать с брокером
- Обеспечивать совместимость между реализациями брокеров

Установка:
```bash
comspoer require enqueue/rdkafka
```

Конфигурация:
```yaml
enqueue:
	transport:
		dsn: '%env(KAFKA_DSN)%'
		global:
			group.id: 'my_group',
			metadata.broker.kist: '%env(KAFKA_BROKER_LIST)%'
	client: ~
```

Создание Producer:
```php
class KafkaController extends AbstractController
{
	private RdKafkaContext $kafkaContext;

	public function __construct(RdKafkaContext $kafkaContext) {
		$this->kafkaContext = $kafkaContext;
	}

	public function __invoke(): Response
	{
		$topic = $this->kafkaContext->createTopic('notifications');
		$message = $this->kafkaContexnt->createMessage('Hello!');
		$this->kafkaContext->createProducer()->send($topic, $message);

		return new Response('Message sent');
	}
}
```

Создание Consumer:
```php
class KafkaNotificationHandler
{
	public function __invoke(Message $message, Context $context): void
	{
	$context->acknowledge($message);
	}
}
```

Запуск Consumer:
```bash
php bin/console enqueue:consume -vvv
```

----
##### Routing VS Pub/Sub VS Streaming

Pub/Sub:
- Издатель (Publisher) отправляет сообщение в **топик** (канал)
- Все подписчики (Subscribers) этого топика получают сообщение
- Пример:
	- Топик news/tech - подписчики получают все новости про технологии

Routing:
- Сообщения отправляются не всем, а выборочно, по определённым правилам.
- Типы маршрутизации в RabbitMQ:
	- Direct Exchange - сообщение идёт в очередь с точным совпадением ключа (routing_key)
	- Topic Exchange - можно использовать маски (`news.*`, `*.tech`)
	- Headers exchange - фильтрация по заголовкам (не по ключу)
- Пример:
	- В очередь `payments` попадают только сообщения с `routing_key=payment`.

Streams:
- Это лог сообщений, где хранятся данные и можно пересчитывать
- Особенности:
	- Сообщения имеют ID и сохраняются
	- Поддержка consumer groups
	- Можно читать с определённого места (XREAD)

## Размеры пакетов и батчинг

Каждый брокер имеет свои ограничения на размер сообщений и оптимальные стратегии пакетной обработки.
Ограничения связаны с:
1. Производительностью (большие сообщения нагружают CPU)
2. Надёжностью (риск переполнения памяти и диска)
3. Архитектурой брокера (например Kafka настроен на потоковую передачу, а Redis на in-memory операции)

#### RabbitMQ

##### Ограничения размера
- По умолчанию 128МБ (зависит от версии и конфигурации)
- Рекомендуемый максимум: 1-10МБ (баланс между пропускной способностью и задержками)
##### Пакетная обработка (batching)
- Поддерживается через:
	- `publisher confirms` - подтверждение доставки пачки
	- `basic.qos` - лимит неподтверждённых сообщений
- Пример пакетной отправки:
```php
$batch = [];
for ($i = 0; $i < 100; $i++) {
	$batch[] = json.encode(['event' => 'click', 'id' => $i]);
}

$this->rabbitMqProducer->publishBatch($batch);
```

С чем связаны ограничения?
- Большие сообщения блокируют очередь (сообщение порядка 1ГБ застопорит отправку маленьких сообщений)
- Затраты на сериализацию/десериализацию

#### Kafka

##### Ограничения размера
- По умолчанию 1МБ (настранивается через `message.max.bytes`)
- Рекомендуемый максимум 10-100МБ (для большиз логов или файлов)

##### Пакетная обработка
- Автоматическая (Kafka сам агрегирует сообщения в пачки перед отправкой)
- Настройки:
	- `linger.ms` - задержка в милисекундах
	- `batch.size` - размер пакета в МБ
- Пример в Symfony:
```php
$topic = $this->kafkaContext->createTopic('logs');
$producer = $this->kafkaContext->createProducer();

for ($i = 0; $i < 1000; $i++) {
	$producer->send($topic, $this->kafkaContext->createMesage("Log entry {$i}"));
}

// Пачка отправится автоматически по достижению linger и batch.size
```

С чем связаны ограничения?
- Партиции и репликация - большие сообщения увеличивают задержку репликации
- Дисковое хранилище - Kafka пишет данные на диск и сообщение на 1ГБ займёт место в несколькиъ партициях

#### Redis

##### Ограничение размера
- Pub/Sub не имеет жёсткого лимита, но лучше ограничиваться в < 1МБ (иначе возможны задержки)
- Streams - до 512МБ на сообщение, но лучше < 10 МБ

##### Пакетная обработка (batching)
- Pub/Sub не миеет встроенного батчинга, каждое сообщение отправляется отдельно.
- Streams поддерживает групповую запись через XADD
- Пример в Symfony:
```php
$redis = new Client();

$pipe = $redis->pipeline();

for ($i = 0; $i < 100; $i++) {
	$pipe->xadd('notifications', '*', ['message' => "Event {$i}"])
}

$pipe->execeute();
```

С чем связаны ограничения?
- In-memory природа. Большие сообщения смогут исчерпать оперативную память.
- Сетевые задержки. Redis работает по TCP и 100МБ запрос может блокировать другие запросы.

#### Рекомендации для продакшена:
##### RabbitMQ
- Разбивать большие файлы на части (chunk upload)
- Использовать подтверждения ack для надёности.

##### Kafka
- Для больших данных лучше использовть внешнее хранилище (S3) а в Kafka передавать только ссылки.
- Настройка `compression.type=lz4` поможет сэкономить трафик.

##### Redis
- Избегай сообщений в > 10МБ - используй Streams вместо Pub/Sub (если нужна история)
- Для частых маленьких сообщений Pub/Sub подходит идеально.


#### Consumer Groups
Это механизм, позволяющий группе потребителей (Consumers) совместно обрабатывать сообщения из одного топика/очереди, распределяя нагрузку между собой.

##### Зачем это нужно?
- Горизонтальное масштабирование: несколько consumers работают параллельно.
- Гарантия порядка: в Kafka сообщения из одной партиции обрабатываются строго одним consumer из группы.
- Отслеживание прогресса: группа запоминает, какие сообщения уже обработаны (через Offsets)

##### Где используется?
- Kafka - ✅
- Redis - ✅
- RabbitMQ - ❎ - вместо этого используются Competing Consumers (round-robin)

##### Использование в Kafka:
- Создаём топик с 3 партициями:
  ```bash
- kafka-topics --create --topic orders --partitions 3 --bootstrap-server localhost:9092
```

- Запускаем 2 консумера в группе order-processors:
  ```bash
- kafka-console-consumer --topic orders --group order-processors --bootstrap-server localhost:9092
- kafka-console-consumer --topic orders --group order-processors --bootstrap-server localhost:9092
```

- Kafka автоматически распределит партиции между consumers
- Если один consumer упадёт, то kafka расрпделит партиции между оставшимися

- Настройка в Symfony:
```php
enqueue:
	transport:
		dsn: 'kafka://localhost:9092'
		group_id: 'order-processors' // имя группы consumers
```

```php
class OrderProcessor
{
public function __invoke(Message $message, Context $context): void
	{
		echo 'Processing' . $message->getBody() . '\n';
		$context->aknowledge($message); // подтверждаем обработку сообщения
	}
}
```

##### Использование в Redis
- Создаём stream и группу:
  ```bash
- XADD orders * product_id 123
- XGROUP CREATE orders order-processors $ MKSTREAM
```

- Чтение сообщений группой:
  ```bash
- XREADGROUP GROUP order-processors consumer1 COUNT 1 STREAMS orders >
- XREADGROUP GROUP order-processors consumer2 COUNT 1 STREAMS orders >
```
- `>` - читать новые, непрочитанные сообщения
- `COUNT 1` - позовлит прочитать только одно сообщение за запрос

- После обработки нужно подтвердить:
  ```bash
- XACK orders order-processors 12345-0
```
- `12345-0` - уникальны идентификатор, который вернёт redis при создании стрима

- Настройка Symfony:
```php
$redis = new Client('tcp://localhost:6379');

$messages = $redis->xreadgroup(
'order-processors',
'consumer1',
['orders' => '>'],
1
);

$redis->xack('orders', 'order-processors', $messages[0]['id']);
```