Каждый брокер имеет свои ограничения на размер сообщений и оптимальные стратегии пакетной обработки.
Ограничения связаны с:
1. Производительностью (большие сообщения нагружают CPU)
2. Надёжностью (риск переполнения памяти и диска)
3. Архитектурой брокера (например Kafka настроен на потоковую передачу, а Redis на in-memory операции)

#### RabbitMQ

##### Ограничения размера
- По умолчанию 128МБ (зависит от версии и конфигурации)
- Рекомендуемый максимум: 1-10МБ (баланс между пропускной способностью и задержками)
##### Пакетная обработка (batching)
- Поддерживается через:
	- `publisher confirms` - подтверждение доставки пачки
	- `basic.qos` - лимит неподтверждённых сообщений
- Пример пакетной отправки:
```php
$batch = [];
for ($i = 0; $i < 100; $i++) {
	$batch[] = json.encode(['event' => 'click', 'id' => $i]);
}

$this->rabbitMqProducer->publishBatch($batch);
```

С чем связаны ограничения?
- Большие сообщения блокируют очередь (сообщение порядка 1ГБ застопорит отправку маленьких сообщений)
- Затраты на сериализацию/десериализацию

#### Kafka

##### Ограничения размера
- По умолчанию 1МБ (настранивается через `message.max.bytes`)
- Рекомендуемый максимум 10-100МБ (для большиз логов или файлов)

##### Пакетная обработка
- Автоматическая (Kafka сам агрегирует сообщения в пачки перед отправкой)
- Настройки:
	- `linger.ms` - задержка в милисекундах
	- `batch.size` - размер пакета в МБ
- Пример в Symfony:
```php
$topic = $this->kafkaContext->createTopic('logs');
$producer = $this->kafkaContext->createProducer();

for ($i = 0; $i < 1000; $i++) {
	$producer->send($topic, $this->kafkaContext->createMesage("Log entry {$i}"));
}

// Пачка отправится автоматически по достижению linger и batch.size
```

С чем связаны ограничения?
- Партиции и репликация - большие сообщения увеличивают задержку репликации
- Дисковое хранилище - Kafka пишет данные на диск и сообщение на 1ГБ займёт место в несколькиъ партициях

#### Redis

##### Ограничение размера
- Pub/Sub не имеет жёсткого лимита, но лучше ограничиваться в < 1МБ (иначе возможны задержки)
- Streams - до 512МБ на сообщение, но лучше < 10 МБ

##### Пакетная обработка (batching)
- Pub/Sub не миеет встроенного батчинга, каждое сообщение отправляется отдельно.
- Streams поддерживает групповую запись через XADD
- Пример в Symfony:
```php
$redis = new Client();

$pipe = $redis->pipeline();

for ($i = 0; $i < 100; $i++) {
	$pipe->xadd('notifications', '*', ['message' => "Event {$i}"])
}

$pipe->execeute();
```

С чем связаны ограничения?
- In-memory природа. Большие сообщения смогут исчерпать оперативную память.
- Сетевые задержки. Redis работает по TCP и 100МБ запрос может блокировать другие запросы.

#### Рекомендации для продакшена:
##### RabbitMQ
- Разбивать большие файлы на части (chunk upload)
- Использовать подтверждения ack для надёности.

##### Kafka
- Для больших данных лучше использовть внешнее хранилище (S3) а в Kafka передавать только ссылки.
- Настройка `compression.type=lz4` поможет сэкономить трафик.

##### Redis
- Избегай сообщений в > 10МБ - используй Streams вместо Pub/Sub (если нужна история)
- Для частых маленьких сообщений Pub/Sub подходит идеально.


#### Consumer Groups
Это механизм, позволяющий группе потребителей (Consumers) совместно обрабатывать сообщения из одного топика/очереди, распределяя нагрузку между собой.

##### Зачем это нужно?
- Горизонтальное масштабирование: несколько consumers работают параллельно.
- Гарантия порядка: в Kafka сообщения из одной партиции обрабатываются строго одним consumer из группы.
- Отслеживание прогресса: группа запоминает, какие сообщения уже обработаны (через Offsets)

##### Где используется?
- Kafka - ✅
- Redis - ✅
- RabbitMQ - ❎ - вместо этого используются Competing Consumers (round-robin)

##### Использование в Kafka:
- Создаём топик с 3 партициями:
  ```bash
- kafka-topics --create --topic orders --partitions 3 --bootstrap-server localhost:9092
```

- Запускаем 2 консумера в группе order-processors:
  ```bash
- kafka-console-consumer --topic orders --group order-processors --bootstrap-server localhost:9092
- kafka-console-consumer --topic orders --group order-processors --bootstrap-server localhost:9092
```

- Kafka автоматически распределит партиции между consumers
- Если один consumer упадёт, то kafka расрпделит партиции между оставшимися

- Настройка в Symfony:
```php
enqueue:
	transport:
		dsn: 'kafka://localhost:9092'
		group_id: 'order-processors' // имя группы consumers
```

```php
class OrderProcessor
{
public function __invoke(Message $message, Context $context): void
	{
		echo 'Processing' . $message->getBody() . '\n';
		$context->aknowledge($message); // подтверждаем обработку сообщения
	}
}
```

##### Использование в Redis
- Создаём stream и группу:
  ```bash
- XADD orders * product_id 123
- XGROUP CREATE orders order-processors $ MKSTREAM
```

- Чтение сообщений группой:
  ```bash
- XREADGROUP GROUP order-processors consumer1 COUNT 1 STREAMS orders >
- XREADGROUP GROUP order-processors consumer2 COUNT 1 STREAMS orders >
```
- `>` - читать новые, непрочитанные сообщения
- `COUNT 1` - позовлит прочитать только одно сообщение за запрос

- После обработки нужно подтвердить:
  ```bash
- XACK orders order-processors 12345-0
```
- `12345-0` - уникальны идентификатор, который вернёт redis при создании стрима

- Настройка Symfony:
```php
$redis = new Client('tcp://localhost:6379');

$messages = $redis->xreadgroup(
'order-processors',
'consumer1',
['orders' => '>'],
1
);

$redis->xack('orders', 'order-processors', $messages[0]['id']);
```

#### Consumer
В качестве consumer (потребителя сообщений может выступать api, микросервисы), то есть любой сервис который читает и обрабатывает сообщения из брокера.

Как это работает:
1. Сервис подключается к брокеру и говорит что является consumer в очереди `emails`
2. Как только сообщение попало в очередь - брокер отправляет его сервису
3. Сервис распоряжается сообщением, например, отправляет email

##### Правила работы consumer:
- Consumer должен быть идемпотентным - одна и та же операция не должна выполняться дважды, даже если сообщение пришло повторно
- Consumer должен подтверждать (ack) сообщения - иначе брокер будет считать сообщение недоставленным и переотправлять его
- Consumer должен обрабатывать ошибки - если что-то пошло не так, сообщения должно уйти в DLQ (Dead Letter Queue) для разбора руками
- Consumer можно масштабировать - в Kafka через consumer-groups, в RabbitMQ competing consumers